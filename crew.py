import os
from dotenv import load_dotenv
from crewai import Crew, Process, LLM
from agents import research_agent, writer_agent, linkedin_agent
from tasks import create_research_task, create_writing_task, create_linkedin_task

# 1. ‡∞™‡∞∞‡±ç‡∞Ø‡∞æ‡∞µ‡∞∞‡∞£ ‡∞µ‡±á‡∞∞‡∞ø‡∞Ø‡∞¨‡±Å‡∞≤‡±ç‡∞∏‡±ç ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç
load_dotenv()

# --- LLM CONFIGURATIONS ---

# High-Performance Model (70b)
smart_llm = LLM(
    model="groq/llama-3.3-70b-versatile",
    api_key=os.getenv("GROQ_API_KEY"),
    temperature=0.3,
    max_tokens=4096,
    max_retries=3
)

# High-Speed Backup Model (8b)
fast_llm = LLM(
    model="groq/llama-3-8b-8192",
    api_key=os.getenv("GROQ_API_KEY"),
    temperature=0.2
)

def run_crew(topic):
    """
    ‡∞à ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç ‡∞Ö‡∞§‡±ç‡∞Ø‡∞Ç‡∞§ ‡∞∏‡±Å‡∞∞‡∞ï‡±ç‡∞∑‡∞ø‡∞§‡∞Æ‡±à‡∞®‡∞¶‡∞ø. 
    1. ‡∞Æ‡±ä‡∞¶‡∞ü ‡∞∞‡±Ä‡∞∏‡±Ü‡∞∞‡±ç‡∞ö‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞ö‡∞ø‡∞®‡±ç‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞µ‡∞æ‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø (Tokens ‡∞Ü‡∞¶‡∞æ ‡∞ö‡±á‡∞Ø‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø).
    2. ‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø‡±á‡∞ü‡∞ø‡∞µ‡±ç ‡∞∞‡±à‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞™‡±Ü‡∞¶‡±ç‡∞¶ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞®‡±Å ‡∞ü‡±ç‡∞∞‡±à ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.
    3. ‡∞í‡∞ï‡∞µ‡±á‡∞≥ ‡∞™‡±Ü‡∞¶‡±ç‡∞¶ ‡∞Æ‡±ã‡∞°‡∞≤‡±ç Rate Limit ‡∞é‡∞∞‡±ç‡∞∞‡∞∞‡±ç ‡∞á‡∞∏‡±ç‡∞§‡±á, ‡∞Ü‡∞ü‡±ã‡∞Æ‡±á‡∞ü‡∞ø‡∞ï‡±ç‚Äå‡∞ó‡∞æ ‡∞ö‡∞ø‡∞®‡±ç‡∞® ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‚Äå‡∞ï‡∞ø ‡∞Æ‡∞æ‡∞∞‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.
    """
    
    # ‡∞™‡±ç‡∞∞‡∞æ‡∞•‡∞Æ‡∞ø‡∞ï ‡∞ï‡±á‡∞ü‡∞æ‡∞Ø‡∞ø‡∞Ç‡∞™‡±Å
    research_agent.llm = fast_llm   # ‡∞∏‡±ç‡∞™‡±Ä‡∞°‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç
    writer_agent.llm = smart_llm     # ‡∞ï‡±ç‡∞µ‡∞æ‡∞≤‡∞ø‡∞ü‡±Ä ‡∞ï‡±ã‡∞∏‡∞Ç
    linkedin_agent.llm = smart_llm   # ‡∞ï‡±ç‡∞µ‡∞æ‡∞≤‡∞ø‡∞ü‡±Ä ‡∞ï‡±ã‡∞∏‡∞Ç

    try:
        # Crew ‡∞Ö‡∞∏‡±Ü‡∞Ç‡∞¨‡±ç‡∞≤‡±Ä
        crew = Crew(
            agents=[research_agent, writer_agent, linkedin_agent],
            tasks=[
                create_research_task(research_agent, topic),
                create_writing_task(writer_agent),
                create_linkedin_task(linkedin_agent)
            ],
            process=Process.sequential,
            embedder={
                "provider": "google",
                "config": {
                    "model": "models/embedding-001",
                    "api_key": os.getenv("GEMINI_API_KEY") or "na"
                }
            } if os.getenv("GEMINI_API_KEY") else None,
            memory=False,
            verbose=True,
            cache=True,
            planning=False 
        )
        return crew.kickoff()

    except Exception as e:
        # ‡∞í‡∞ï‡∞µ‡±á‡∞≥ Rate Limit ‡∞é‡∞∞‡±ç‡∞∞‡∞∞‡±ç ‡∞µ‡∞∏‡±ç‡∞§‡±á, ‡∞Ö‡∞®‡±ç‡∞®‡∞ø ‡∞è‡∞ú‡±Ü‡∞Ç‡∞ü‡±ç‡∞≤‡∞®‡±Å Fast LLM ‡∞ï‡∞ø ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≥‡±Ä ‡∞∞‡∞®‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø
        if "rate_limit_exceeded" in str(e).lower() or "429" in str(e):
            print("üö® Smart LLM Limit Reached. Switching to Backup Fast LLM...")
            writer_agent.llm = fast_llm
            linkedin_agent.llm = fast_llm
            # ‡∞Æ‡∞≥‡±ç‡∞≥‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞Ç
            return crew.kickoff()
        else:
            raise e
