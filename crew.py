import os
from dotenv import load_dotenv
from crewai import Crew, Process, LLM
from agents import research_agent, writer_agent, linkedin_agent
from tasks import create_research_task, create_writing_task, create_linkedin_task

# 1. ‡∞™‡∞∞‡±ç‡∞Ø‡∞æ‡∞µ‡∞∞‡∞£ ‡∞µ‡±á‡∞∞‡∞ø‡∞Ø‡∞¨‡±Å‡∞≤‡±ç‡∞∏‡±ç ‡∞≤‡±ã‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç
load_dotenv()

# --- LLM CONFIGURATIONS ---

# High-Performance Model (70b) - ‡∞ï‡±ç‡∞µ‡∞æ‡∞≤‡∞ø‡∞ü‡±Ä ‡∞∞‡±à‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç
smart_llm = LLM(
    model="groq/llama-3.3-70b-versatile",
    api_key=os.getenv("GROQ_API_KEY"),
    temperature=0.3,
    max_tokens=4096
)

# High-Speed Model (8b) - ‡∞µ‡±á‡∞ó‡∞µ‡∞Ç‡∞§‡∞Æ‡±à‡∞® ‡∞∞‡±Ä‡∞∏‡±Ü‡∞∞‡±ç‡∞ö‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç
fast_llm = LLM(
    model="groq/llama-3-8b-8192",
    api_key=os.getenv("GROQ_API_KEY"),
    temperature=0.2
)

def run_crew(topic):
    """
    ‡∞à ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç Hybrid ‡∞∏‡±Ü‡∞ü‡∞™‡±ç‚Äå‡∞®‡±Å ‡∞∞‡∞®‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø:
    - ‡∞∞‡±Ä‡∞∏‡±Ü‡∞∞‡±ç‡∞ö‡±ç: 8b ‡∞Æ‡±ã‡∞°‡∞≤‡±ç (Speed & Saving)
    - ‡∞∞‡±à‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç: 70b ‡∞Æ‡±ã‡∞°‡∞≤‡±ç (Quality)
    """
    
    # ‡∞è‡∞ú‡±Ü‡∞Ç‡∞ü‡±ç‡∞≤‡∞ï‡±Å ‡∞Æ‡±ã‡∞°‡∞≤‡±ç‡∞∏‡±ç ‡∞ï‡±á‡∞ü‡∞æ‡∞Ø‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç
    research_agent.llm = fast_llm   
    writer_agent.llm = smart_llm     
    linkedin_agent.llm = smart_llm   

    # Crew ‡∞Ö‡∞∏‡±Ü‡∞Ç‡∞¨‡±ç‡∞≤‡±Ä
    crew = Crew(
        agents=[research_agent, writer_agent, linkedin_agent],
        tasks=[
            create_research_task(research_agent, topic),
            create_writing_task(writer_agent),
            create_linkedin_task(linkedin_agent)
        ],
        process=Process.sequential,
        
        # üö® ‡∞é‡∞∞‡±ç‡∞∞‡∞∞‡±ç ‡∞∞‡∞æ‡∞ï‡±Å‡∞Ç‡∞°‡∞æ ‡∞á‡∞ï‡±ç‡∞ï‡∞° Embedder ‡∞®‡∞ø ‡∞§‡±Ä‡∞∏‡∞ø‡∞µ‡±á‡∞∏‡∞ø ‡∞°‡∞ø‡∞´‡∞æ‡∞≤‡±ç‡∞ü‡±ç ‡∞∏‡±Ü‡∞ü‡±ç ‡∞ö‡±á‡∞∂‡∞æ‡∞Ç
        memory=False, 
        verbose=True,
        cache=True,
        planning=False # OpenAI ‡∞ï‡±Ä ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞≤‡±á‡∞ï‡±Å‡∞Ç‡∞°‡∞æ ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø
    )

    return crew.kickoff()
