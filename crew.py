from crewai import Crew, Process
from crewai.llm import LLM
import os

# agents.py ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å tasks.py ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞´‡∞Ç‡∞ï‡±ç‡∞∑‡∞®‡±ç‡∞≤‡∞®‡±Å ‡∞á‡∞Ç‡∞™‡±ã‡∞∞‡±ç‡∞ü‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Æ‡±Å
try:
    from agents import (
        create_research_agent, 
        create_writer_agent, 
        create_linkedin_manager_agent
    )
    from tasks import (
        create_research_task, 
        create_writing_task, 
        create_linkedin_task
    )
except ImportError as e:
    print(f"Error: Make sure agents.py and tasks.py exist in the same folder. {e}")

def run_crew(topic: str) -> str:
    """
    ‡∞∞‡∞ø‡∞∏‡±Ü‡∞∞‡±ç‡∞ö‡±ç, ‡∞∞‡±à‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞≤‡∞ø‡∞Ç‡∞ï‡±ç‡∞°‡±ç‚Äå‡∞á‡∞®‡±ç ‡∞´‡∞æ‡∞∞‡±ç‡∞Æ‡∞æ‡∞ü‡∞ø‡∞Ç‡∞ó‡±ç ‡∞™‡±ç‡∞∞‡∞ï‡±ç‡∞∞‡∞ø‡∞Ø‡∞®‡±Å ‡∞®‡∞ø‡∞∞‡±ç‡∞µ‡∞π‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.
    """
    
    # 1. LLM Configuration (Groq Llama 3.1)
    # base_url ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç ‡∞µ‡∞≤‡±ç‡∞≤ OpenAI ‡∞é‡∞∞‡±ç‡∞∞‡∞∞‡±ç ‡∞∞‡∞æ‡∞¶‡±Å
    llm = LLM(
        model="groq/llama-3.1-8b-instant", # ‡∞µ‡±á‡∞ó‡∞µ‡∞Ç‡∞§‡∞Æ‡±à‡∞® ‡∞∞‡±Ü‡∞∏‡±ç‡∞™‡∞æ‡∞®‡±ç‡∞∏‡±ç ‡∞ï‡±ã‡∞∏‡∞Ç
        api_key=os.getenv("GROQ_API_KEY"),
        base_url="https://api.groq.com/openai/v1", # ‡∞á‡∞¶‡∞ø ‡∞§‡∞™‡±ç‡∞™‡∞®‡∞ø‡∞∏‡∞∞‡∞ø
        temperature=0.5, # ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±ç ‡∞µ‡∞æ‡∞°‡∞ï‡∞Ç ‡∞§‡∞ó‡±ç‡∞ó‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø
        max_tokens=2048
    )

    # 2. ‡∞è‡∞ú‡±Ü‡∞Ç‡∞ü‡±ç‡∞≤ ‡∞§‡∞Ø‡∞æ‡∞∞‡±Ä
    researcher = create_research_agent(llm)
    writer = create_writer_agent(llm)
    linkedin_manager = create_linkedin_manager_agent(llm)

    # 3. ‡∞ü‡∞æ‡∞∏‡±ç‡∞ï‡±ç‚Äå‡∞≤ ‡∞§‡∞Ø‡∞æ‡∞∞‡±Ä
    research_task = create_research_task(researcher, topic)
    writing_task = create_writing_task(writer)
    linkedin_task = create_linkedin_task(linkedin_manager)

    # 4. Crew Formation
    crew = Crew(
        agents=[researcher, writer, linkedin_manager],
        tasks=[research_task, writing_task, linkedin_task],
        process=Process.sequential, 
        verbose=True,                
        memory=True,                 
        cache=True                   
    )

    try:
        # 5. Execution
        print(f"üöÄ Launching Crew for topic: {topic}")
        result = crew.kickoff()
        
        # CrewAI 0.28+ ‡∞µ‡±Ü‡∞∞‡±ç‡∞∑‡∞®‡±ç‡∞≤‡∞≤‡±ã 'raw' ‡∞Ö‡∞µ‡±Å‡∞ü‡±ç‚Äå‡∞™‡±Å‡∞ü‡±ç‚Äå‡∞®‡±Å ‡∞™‡∞Ç‡∞™‡±Å‡∞§‡∞æ‡∞Æ‡±Å
        return result.raw if hasattr(result, 'raw') else str(result)
        
    except Exception as e:
        # Rate limit ‡∞µ‡∞∏‡±ç‡∞§‡±á 20 ‡∞∏‡±Ü‡∞ï‡∞®‡±ç‡∞≤‡±Å ‡∞Ü‡∞ó‡∞Æ‡∞®‡∞ø ‡∞∏‡±Ç‡∞ö‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø
        if "rate_limit" in str(e).lower():
            return "Error: Groq Rate Limit reached. Please wait 20 seconds and try again."
        return f"Error in Crew Execution: {str(e)}"

if __name__ == "__main__":
    test_topic = "Future of AI Agents"
    print(run_crew(test_topic))
